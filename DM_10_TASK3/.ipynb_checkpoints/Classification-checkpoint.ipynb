{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION PLAN:\n",
    "We collected the labelled data from 2 different origins:\n",
    "1. **KMeans Clustering** result (which will be called **original data**): 3 distinct classes, one of which is highly **imbalanced**\n",
    "2. **Fuzzy Kmeans Clustering** result (which will be called **fuzzy data**): 3 distinct classes, not on same magnitude but also not particularly imbalanced\n",
    "\n",
    "Different approaches will be evaluated:\n",
    "* Apply classification on original training set i.e. high imbalance in data\n",
    "* Apply classification on oversampled original training set (robust oversampling method -> SMOTE)\n",
    "* Apply classification on oversampled original training set and test set (robust oversampling method -> SMOTE)\n",
    "* Apply classification on fuzzy training set i.e. more balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pydotplus\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import Image \n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, make_scorer, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITY FUNCTIONS\n",
    "\n",
    "# transform categorical attributes in numerical \n",
    "def discretize_data(dataset, variables):\n",
    "    for variable in variables:\n",
    "        #get the unique variable's values\n",
    "        var = sorted(dataset[variable].unique())\n",
    "        \n",
    "        #generate a mapping from the variable's values to the number representation  \n",
    "        mapping = dict(zip(var, range(0, len(var) + 1)))\n",
    "\n",
    "        #add a new colum with the number representation of the variable\n",
    "        dataset[variable+'_num'] = dataset[variable].map(mapping).astype(int)\n",
    "    return dataset\n",
    "\n",
    "# pretty printing of metrics computed on test set\n",
    "def report_scores(test_label, test_pred):\n",
    "    print(classification_report(test_label, \n",
    "                            test_pred, \n",
    "                            target_names=classes, zero_division=0)) \n",
    "# (to avoid exagerated warnings) zero division = 0 makes sure that no warnings \n",
    "# are raised even if no classification on a certain class happens (and it can happen in multiple cases in this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKING ON ORIGINAL DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting dataset\n",
    "df = pd.read_csv('datasets/clustered_dataframe.csv', sep='\\t', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a look at data distribution between classes\n",
    "for label in df['Label'].unique():\n",
    "    print(label,\"elements in dataset:\",len(df[df['Label'] == label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only have 2 categorical attributes, discretize them and get rid of them \n",
    "# (also get rid of attributes which lead in our experiments to bad classification)\n",
    "df = discretize_data(df,['MaxOrderMonth','MaxOrderDay','Label'])\n",
    "df.drop(columns=['MaxOrderMonth','MaxOrderDay','Label'], inplace=True, errors='ignore')\n",
    "df.drop(columns=['SETSaleQta','SESaleQtaOrder','MinPSale','MaxPSale'], inplace=True, errors='ignore')\n",
    "df_class = df.copy()\n",
    "df_class.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we keep true labels apart\n",
    "label = df_class.pop('Label_num')\n",
    "# we split dataset in training and test dataset. The use of stratify assures we keep correct class proportions in training and test\n",
    "train_set, test_set, train_label, test_label = train_test_split(df_class, label, stratify = label, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION on ORIGINAL TRAINING SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (only for illustrating the method, we apply this to make an example of high explainability in classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters based on various trial and errors\n",
    "dt = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                  max_depth=3, \n",
    "                                  min_samples_split=3, min_samples_leaf=8)\n",
    "dt = dt.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualization of dt\n",
    "classes = ['High_Spend','Low_Spend','Med_Spend']\n",
    "dot_data = tree.export_graphviz(dt, out_file=None,\n",
    "                         feature_names=list(train_set.columns),\n",
    "                         class_names=classes,  #in transforming to numerical this order is mapped to 0,1,2 because of lexicographical\n",
    "                         filled=True, rounded=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and evaluate results on training and test set\n",
    "train_pred_dt = dt.predict(train_set)\n",
    "test_pred_dt = dt.predict(test_set)\n",
    "\n",
    "print('Accuracy training set ', metrics.accuracy_score(train_label, train_pred_dt))\n",
    "print('Accuracy test set ', metrics.accuracy_score(test_label, test_pred_dt))\n",
    "print('Precision training set ', metrics.precision_score(train_label, train_pred_dt, average='weighted'))\n",
    "print('Recall training set ', metrics.recall_score(train_label, train_pred_dt, average='weighted'))\n",
    "print('F1 score trainig set ', metrics.f1_score(train_label, train_pred_dt, average='weighted'))\n",
    "print('Support training set ', metrics.precision_recall_fscore_support(train_label, train_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plot_confusion_matrix(dt, test_set, test_label)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First do a grid search for correct parameter setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter ranges we want to try, then run the grid search\n",
    "num_estimators = 30\n",
    "param_dist = {\"max_depth\": [3,5,6,7,8,9,10,11,12,None],\n",
    "              \"max_features\": sp_randint(1, 10),\n",
    "              \"min_samples_split\": sp_randint(3, 20),\n",
    "              \"min_samples_leaf\": sp_randint(5, 20),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"entropy\", \"gini\"]}\n",
    "n_iter_search = 50\n",
    "clf = RandomForestClassifier(n_estimators=num_estimators)\n",
    "grid_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=-1, \n",
    "                            scoring=make_scorer(accuracy_score))\n",
    "grid_search.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize insights on best performing model individuated\n",
    "print('Best setting parameters ', grid_search.cv_results_['params'][0])\n",
    "print('Mean and std of this setting ', grid_search.cv_results_['mean_test_score'][0], \n",
    "      grid_search.cv_results_['std_test_score'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set and training the specified random forest\n",
    "rf = RandomForestClassifier(n_estimators=30, \n",
    "                             criterion=grid_search.cv_results_['params'][0]['criterion'],\n",
    "                             max_features=grid_search.cv_results_['params'][0]['max_features'],\n",
    "                             max_depth=grid_search.cv_results_['params'][0]['max_depth'], \n",
    "                             min_samples_split=grid_search.cv_results_['params'][0]['min_samples_split'],\n",
    "                             min_samples_leaf=grid_search.cv_results_['params'][0]['min_samples_leaf'],\n",
    "                             bootstrap=grid_search.cv_results_['params'][0]['bootstrap']) \n",
    "rf = rf.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test and visualize results\n",
    "test_pred_rf = rf.predict(test_set)\n",
    "report_scores(test_label, test_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest is composed of lots of dt, visualize one just for fun\n",
    "dot_data = tree.export_graphviz(rf[0], out_file=None,\n",
    "                         feature_names=list(train_set.columns),\n",
    "                         class_names=classes,\n",
    "                         filled=True, rounded=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit naive bayes model, predict on test and see results\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_set, train_label)\n",
    "\n",
    "test_pred_gnb = gnb.predict(test_set)\n",
    "\n",
    "report_scores(test_label,test_pred_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit knn model, predict on test and see results\n",
    "knn = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree', metric='minkowski').fit(train_set, train_label)\n",
    "\n",
    "test_pred_knn = knn.predict(test_set)\n",
    "\n",
    "report_scores(test_label,test_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit svm model, predict on test and see results\n",
    "svm = SVC(kernel='sigmoid', C=0.6, gamma='scale', probability=True)\n",
    "svm.fit(train_set, train_label)\n",
    "\n",
    "test_pred_svm = svm.predict(test_set)\n",
    "\n",
    "report_scores(test_label, test_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION on OVERSAMPLED TRAINING SET (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTE** is a different stratification method which applies oversampling to the classes. The difference between this method and the basic oversampling stands in the generation of new data:\n",
    "* in the basic oversampling, original data is simply copied to create exact (but additional) new data\n",
    "* in SMOTE oversampling, original data is used to create new data which copies the old one adding a [0,1] **perturbation**, hence generating truly new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create oversampled data\n",
    "strat = {1: Counter(train_label)[1], 2: Counter(train_label)[2], 0: Counter(train_label)[2] }\n",
    "smote = SMOTE(\n",
    "    sampling_strategy=strat,    # resample all classes but the majority one\n",
    "    k_neighbors=5\n",
    ")\n",
    "\n",
    "train_set_smote, train_label_smote = smote.fit_resample(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data distribution\n",
    "Counter(train_label_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try grid search again, on this more **balanced** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and run the grid search\n",
    "clf_smote = RandomForestClassifier(n_estimators=num_estimators)\n",
    "grid_search_smote = RandomizedSearchCV(clf_smote, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=-1, \n",
    "                            scoring=make_scorer(accuracy_score))\n",
    "grid_search_smote.fit(train_set_smote, train_label_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize insights on best performing model individuated\n",
    "print('Best setting parameters ', grid_search_smote.cv_results_['params'][0])\n",
    "print('Mean and std of this setting ', grid_search_smote.cv_results_['mean_test_score'][0], \n",
    "      grid_search_smote.cv_results_['std_test_score'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set and training the specified random forest\n",
    "rf_smote = RandomForestClassifier(n_estimators=num_estimators, \n",
    "                             criterion=grid_search_smote.cv_results_['params'][0]['criterion'],\n",
    "                             max_features=grid_search_smote.cv_results_['params'][0]['max_features'],\n",
    "                             max_depth=grid_search_smote.cv_results_['params'][0]['max_depth'], \n",
    "                             min_samples_split=grid_search_smote.cv_results_['params'][0]['min_samples_split'],\n",
    "                             min_samples_leaf=grid_search_smote.cv_results_['params'][0]['min_samples_leaf'],\n",
    "                             bootstrap=grid_search_smote.cv_results_['params'][0]['bootstrap'])\n",
    "rf_smote = rf_smote.fit(train_set_smote, train_label_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test and visualize results\n",
    "test_pred_rf = rf_smote.predict(test_set)\n",
    "report_scores(test_label, test_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit naive bayes model, predict on test and see results\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_set_smote, train_label_smote)\n",
    "\n",
    "test_pred_gnb = gnb.predict(test_set)\n",
    "\n",
    "report_scores(test_label,test_pred_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit knn model, predict on test and see results\n",
    "knn = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree', metric='minkowski').fit(train_set_smote, train_label_smote)\n",
    "\n",
    "test_pred_knn = knn.predict(test_set)\n",
    "\n",
    "report_scores(test_label,test_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit svm model, predict on test and see results\n",
    "svm = SVC(kernel='sigmoid', C=0.6, gamma='scale', probability=True)\n",
    "svm.fit(train_set_smote, train_label_smote)\n",
    "\n",
    "test_pred_svm = svm.predict(test_set)\n",
    "\n",
    "report_scores(test_label, test_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION on OVERSAMPLED TRAINING SET and TEST SET (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before starting classification we apply stratification to test set to have more data in less populated class\n",
    "# we do this because otherwise our test set would be populated of < 10 elements for High_Spend class, giving a susceptible evaluation  \n",
    "strat = {1: Counter(test_label)[1], 2: Counter(test_label)[2], 0: Counter(test_label)[2] }\n",
    "smote = SMOTE(\n",
    "    sampling_strategy=strat,    # resample all classes but the majority one\n",
    "    k_neighbors=5\n",
    ")\n",
    "test_set, test_label = smote.fit_resample(test_set, test_label)\n",
    "\n",
    "# visualize data distribution in TEST\n",
    "Counter(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(test_set.iloc[:, 4].values, test_set.iloc[:, 0].values, c=test_label.values, s=25, cmap='winter');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data distribution in TRAINING\n",
    "Counter(train_label_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try grid search again, on this more balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and run the grid search\n",
    "clf_smote = RandomForestClassifier(n_estimators=num_estimators)\n",
    "grid_search_smote = RandomizedSearchCV(clf_smote, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=-1, \n",
    "                            scoring=make_scorer(accuracy_score))\n",
    "grid_search_smote.fit(train_set_smote, train_label_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize insights on best performing model individuated\n",
    "print('Best setting parameters ', grid_search_smote.cv_results_['params'][0])\n",
    "print('Mean and std of this setting ', grid_search_smote.cv_results_['mean_test_score'][0], \n",
    "      grid_search_smote.cv_results_['std_test_score'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set and training the specified random forest\n",
    "rf_smote = RandomForestClassifier(n_estimators=num_estimators, \n",
    "                             criterion=grid_search_smote.cv_results_['params'][0]['criterion'],\n",
    "                             max_features=grid_search_smote.cv_results_['params'][0]['max_features'],\n",
    "                             max_depth=grid_search_smote.cv_results_['params'][0]['max_depth'], \n",
    "                             min_samples_split=grid_search_smote.cv_results_['params'][0]['min_samples_split'],\n",
    "                             min_samples_leaf=grid_search_smote.cv_results_['params'][0]['min_samples_leaf'],\n",
    "                             bootstrap=grid_search_smote.cv_results_['params'][0]['bootstrap'])\n",
    "rf_smote = rf_smote.fit(train_set_smote, train_label_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test and visualize results\n",
    "test_pred_rf = rf_smote.predict(test_set)\n",
    "report_scores(test_label, test_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit naive bayes model, predict on test and see results\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_set_smote, train_label_smote)\n",
    "\n",
    "test_pred_gnb = gnb.predict(test_set)\n",
    "\n",
    "report_scores(test_label,test_pred_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit knn model, predict on test and see results\n",
    "knn = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree', metric='minkowski').fit(train_set_smote, train_label_smote)\n",
    "\n",
    "test_pred_knn = knn.predict(test_set)\n",
    "\n",
    "report_scores(test_label,test_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit svm model, predict on test and see results\n",
    "svm = SVC(kernel='sigmoid', C=0.6, gamma='scale', probability=True)\n",
    "svm.fit(train_set_smote, train_label_smote)\n",
    "\n",
    "test_pred_svm = svm.predict(test_set)\n",
    "\n",
    "report_scores(test_label, test_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKING ON FUZZY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting dataset\n",
    "df_f = pd.read_csv('datasets/clustered_fuzzy_dataframe.csv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only have 2 categorical attributes, discretize them and get rid of them \n",
    "# (also get rid of attributes which lead in our experiments to bad classification)\n",
    "df_f = discretize_data(df_f,['MaxOrderMonth','MaxOrderDay','Label'])\n",
    "df_f.drop(columns=['MaxOrderMonth','MaxOrderDay','Label'], inplace=True, errors='ignore')\n",
    "df_f.drop(columns=['SETSaleQta','SESaleQtaOrder','MinPSale','MaxPSale'], inplace=True, errors='ignore')\n",
    "df_f_class = df_f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we keep true labels apart\n",
    "label = df_f_class.pop('Label_num')\n",
    "# we split dataset in training and test dataset. The use of stratify assures we keep correct class proportions in training and test\n",
    "train_set_f, test_set_f, train_label_f, test_label_f = train_test_split(df_f_class, label, stratify = label, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (only for illustrating the method, we apply this to make an example of high explainability in classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters based on various trial and errors\n",
    "dt_f = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                  max_depth=3, \n",
    "                                  min_samples_split=3, min_samples_leaf=8)\n",
    "dt_f = dt_f.fit(train_set_f, train_label_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualization of dt\n",
    "dot_data_f = tree.export_graphviz(dt_f, out_file=None,\n",
    "                         feature_names=list(train_set_f.columns),\n",
    "                         class_names=classes,  #in transforming to numerical this order is mapped to 0,1,2 because of lexicographical\n",
    "                         filled=True, rounded=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data_f)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on training and test set\n",
    "train_pred_dt_f = dt_f.predict(train_set_f)\n",
    "test_pred_dt_f = dt_f.predict(test_set_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results\n",
    "report_scores(test_label_f, test_pred_dt_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do a grid search for correct parameter setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter ranges we want to try, then run the grid search\n",
    "clf_f = RandomForestClassifier(n_estimators=30)\n",
    "grid_search_f = RandomizedSearchCV(clf_f, param_distributions=param_dist, \n",
    "                            n_iter=n_iter_search, \n",
    "                            n_jobs=-1, \n",
    "                            scoring=make_scorer(accuracy_score))\n",
    "grid_search_f.fit(train_set_f, train_label_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize insights on best performing model individuated\n",
    "print('Best setting parameters ', grid_search_f.cv_results_['params'][0])\n",
    "print('Mean and std of this setting ', grid_search_f.cv_results_['mean_test_score'][0], \n",
    "      grid_search_f.cv_results_['std_test_score'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set and training the specified random forest\n",
    "rf_f = RandomForestClassifier(n_estimators=num_estimators, \n",
    "                             criterion=grid_search_f.cv_results_['params'][0]['criterion'],\n",
    "                             max_features=grid_search_f.cv_results_['params'][0]['max_features'],\n",
    "                             max_depth=grid_search_f.cv_results_['params'][0]['max_depth'], \n",
    "                             min_samples_split=grid_search_f.cv_results_['params'][0]['min_samples_split'],\n",
    "                             min_samples_leaf=grid_search_f.cv_results_['params'][0]['min_samples_leaf'],\n",
    "                             bootstrap=grid_search_f.cv_results_['params'][0]['bootstrap']) \n",
    "rf_f = rf_f.fit(train_set_f, train_label_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test and visualize results\n",
    "test_pred_rf_f = rf_f.predict(test_set_f)\n",
    "report_scores(test_label_f, test_pred_rf_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest is composed of lots of dt, visualize one just for fun\n",
    "dot_data_f = tree.export_graphviz(rf_f[0], out_file=None,\n",
    "                         feature_names=list(train_set_f.columns),\n",
    "                         class_names=classes,\n",
    "                         filled=True, rounded=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data_f)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit naive bayes model, predict on test and see results\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_set_f, train_label_f)\n",
    "\n",
    "test_pred_gnb = gnb.predict(test_set_f)\n",
    "\n",
    "report_scores(test_label_f,test_pred_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit knn model, predict on test and see results\n",
    "knn = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree', metric='minkowski').fit(train_set_f, train_label_f)\n",
    "\n",
    "test_pred_knn = knn.predict(test_set_f)\n",
    "\n",
    "report_scores(test_label_f,test_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit svm model, predict on test and see results\n",
    "svm = SVC(kernel='sigmoid', C=0.6, gamma='scale', probability=True)\n",
    "svm.fit(train_set_f, train_label_f)\n",
    "\n",
    "test_pred_svm_f = svm.predict(test_set_f)\n",
    "\n",
    "report_scores(test_label_f, test_pred_svm_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary functions\n",
    "The following functions are useful in many sections of this notebook, therefore they\n",
    "are put here at the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Function to normalize the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_dataset(df):\n",
    "    cols = df.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    df = scaler.fit_transform(df.values)\n",
    "    df = pd.DataFrame(df, columns=cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Function to print the dataset's composition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_dataset_composition(train_set, train_labels, test_set, test_labels):\n",
    "    assert(len(train_set) == len(train_labels))\n",
    "    assert(len(test_set) == len(test_labels))\n",
    "    print(f\"{len(train_labels)} training samples:\")\n",
    "    print(f\"\\t- {len(train_labels[train_labels == 0])} samples for the class High_Spend\")\n",
    "    print(f\"\\t- {len(train_labels[train_labels == 1])} samples for the class Low_Spend\")\n",
    "    print(f\"\\t- {len(train_labels[train_labels == 2])} samples for the class Med_Spend\")\n",
    "    print(f\"\\n{len(test_labels)} test samples:\")\n",
    "    print(f\"\\t- {len(test_labels[test_labels == 0])} samples for the class High_Spend\")\n",
    "    print(f\"\\t- {len(test_labels[test_labels == 1])} samples for the class Low_Spend\")\n",
    "    print(f\"\\t- {len(test_labels[test_labels == 2])} samples for the class Med_Spend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create the NN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creates and returns a Keras NN model\n",
    "def create_nn(size):\n",
    "    \"\"\"\n",
    "    Characteristics:\n",
    "        * 4 fully connected layers\n",
    "            * the first 3 have 32 units\n",
    "            * the last one has as many units as the number of classes, thus 3\n",
    "\n",
    "        * activation function:\n",
    "            * ReLU for the first 3 layers\n",
    "            * Softmax for the output layer\n",
    "\n",
    "        * Dropout of 0.2 is applied after every layer\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_shape=(1,size)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compile and fit the NN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compile_fit(model, training_set, training_labels, epochs):\n",
    "    \"\"\"\n",
    "    Compile and fits the model\n",
    "\n",
    "    :param training_labels:\n",
    "    :param training_set:\n",
    "    :param model: Keras NN model to train\n",
    "    :return: history of training to plot the metrics\n",
    "    \"\"\"\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(training_labels[0])\n",
    "    hist = model.fit(\n",
    "        training_set,\n",
    "        training_labels,\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to plot the training results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_train_results(train_history):\n",
    "    acc = train_history.history['accuracy']\n",
    "    val_acc = train_history.history['val_accuracy']\n",
    "    loss = train_history.history['loss']\n",
    "    val_loss = train_history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'bo', label='Validation Accuracy')\n",
    "    plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'ro', label='Validation Loss')\n",
    "    plt.title('Training and validation Acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy & Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base dataframe\n",
    "Labels come from _K-means_ clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Drop categorical columns and keep only the corresponding numerical ones\n",
    "df.drop(columns=['MaxOrderMonth','Label'], inplace=True, errors='ignore')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the labels from the dataframe and store them in a variable (pandas.Series)\n",
    "labels = df.pop('Label_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.boxplot(rot=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = normalize_dataset(df)\n",
    "df.boxplot(rot=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataframe to create training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set, test_set, train_labels, test_labels = train_test_split(df, labels, stratify=labels, test_size=0.30)\n",
    "print_dataset_composition(train_set, train_labels, test_set, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Encode labels with one-hot\n",
    "train_labels = to_categorical(train_labels, 3)\n",
    "test_labels = to_categorical(test_labels, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Neural Network, compile it and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nn = create_nn(len(df.columns))\n",
    "history = compile_fit(nn, train_set, train_labels, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_train_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions = nn.predict_classes(test_set)\n",
    "test_predictions = to_categorical(test_predictions, 3)\n",
    "report_scores(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base dataframe with SMOTE oversampling\n",
    "Labels come from _K-Means_ clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize and SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Normalize the dataset\n",
    "cols = df.columns\n",
    "scaler = MinMaxScaler()\n",
    "df = scaler.fit_transform(df.values)\n",
    "df = pd.DataFrame(df, columns=cols)\n",
    "\n",
    "# Pick validation set from the complete df\n",
    "df, val_set, labels, val_labels = train_test_split(df, labels, stratify=labels, test_size=0.30)\n",
    "\n",
    "# Divide the dataframe to create training and testing sets\n",
    "train_set, test_set, train_labels, test_labels = train_test_split(df, labels, stratify=labels, test_size=0.30)\n",
    "\n",
    "# SMOTE --> balance the number of entries of each class\n",
    "smote = SMOTE(\n",
    "    sampling_strategy='not majority',    # resample all classes but the majority one\n",
    "    k_neighbors=4\n",
    ")\n",
    "train_set, train_labels = smote.fit_resample(train_set, train_labels)\n",
    "test_set, test_labels = smote.fit_resample(test_set, test_labels)\n",
    "\n",
    "assert(len(train_set) == len(train_labels))\n",
    "assert(len(val_set) == len(val_labels))\n",
    "assert(len(test_set) == len(test_labels))\n",
    "print(f\"\\n{len(train_labels)} training samples:\")\n",
    "print(f\"\\t- {len(train_labels[train_labels == 0])} samples for the class High_Spend\")\n",
    "print(f\"\\t- {len(train_labels[train_labels == 1])} samples for the class Low_Spend\")\n",
    "print(f\"\\t- {len(train_labels[train_labels == 2])} samples for the class Med_Spend\")\n",
    "print(f\"\\n{len(test_labels)} validation samples:\")\n",
    "print(f\"\\t- {len(val_labels[val_labels == 0])} samples for the class High_Spend\")\n",
    "print(f\"\\t- {len(val_labels[val_labels == 1])} samples for the class Low_Spend\")\n",
    "print(f\"\\t- {len(val_labels[val_labels == 2])} samples for the class Med_Spend\")\n",
    "print(f\"\\n{len(test_labels)} test samples:\")\n",
    "print(f\"\\t- {len(test_labels[test_labels == 0])} samples for the class High_Spend\")\n",
    "print(f\"\\t- {len(test_labels[test_labels == 1])} samples for the class Low_Spend\")\n",
    "print(f\"\\t- {len(test_labels[test_labels == 2])} samples for the class Med_Spend\")\n",
    "\n",
    "# Encode labels with one-hot\n",
    "train_labels = to_categorical(train_labels, 3)\n",
    "val_labels = to_categorical(val_labels, 3)\n",
    "test_labels = to_categorical(test_labels, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Neural Network, compile it and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nn = Sequential([\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "nn.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = nn.fit(\n",
    "    train_set,\n",
    "    train_labels,\n",
    "    epochs=27,\n",
    "    batch_size=32,\n",
    "    validation_data=(val_set, val_labels),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_train_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions = nn.predict_classes(test_set)\n",
    "test_predictions = to_categorical(test_predictions, 3)\n",
    "report_scores(test_labels, test_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe coming from Fuzzy C-Means\n",
    "Labels come from _Fuzzy C-Means_ clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the labels from the dataframe and store them in a variable (pandas.Series)\n",
    "labels = df_f.pop('Label_num')\n",
    "\n",
    "#Normalize the dataset\n",
    "df_f = normalize_dataset(df_f)\n",
    "\n",
    "# Divide the dataframe to create training and testing sets\n",
    "train_set, test_set, train_labels, test_labels = train_test_split(df_f, labels, stratify=labels, test_size=0.30)\n",
    "print_dataset_composition(train_set, train_labels, test_set, test_labels)\n",
    "\n",
    "# Encode labels with one-hot\n",
    "train_labels = to_categorical(train_labels, 3)\n",
    "test_labels = to_categorical(test_labels, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Neural Network, compile it and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn = create_nn(len(df_f.columns))\n",
    "history = compile_fit(nn, train_set, train_labels, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_train_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions = nn.predict_classes(test_set)\n",
    "test_predictions = to_categorical(test_predictions, 3)\n",
    "report_scores(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis the dataset *customer_dataframe_big.csv* will be used, since it contains all the features for the customers.\n",
    "Then, joining with the dataset created from Fuzzy K-Means we add the labeling to the various customers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/clustered_fuzzy_dataframe.csv', sep='\\t', index_col=0)\n",
    "df_customer = pd.read_csv('datasets/customer_dataframe_big.csv', sep='\\t', index_col=0)\n",
    "\n",
    "df_customer.set_index(\"CustomerID\", inplace = True)\n",
    "df_customer['Label'] = df['Label']\n",
    "\n",
    "# Size of different classes in the dataset\n",
    "print(\"-------------------------\")\n",
    "for i in ['Low_Spend', 'Med_Spend', 'High_Spend']:\n",
    "    print(i, len(df_customer[df_customer['Label'] == i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target of this analysis is to use all the features that are not exploited by the clustering to assign the customers to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop all the features that are not time dependent and not usefull to generalize the behaviour of a customer\n",
    "df_customer = discretize_data(df_customer,['MaxOrderMonth','Label'])\n",
    "df_aux = df_customer.drop(columns=['TProd', 'MaxPO', 'MinPO', 'MeanProdOrder', 'TSaleWRet', 'MinPSale', 'MaxPSale', 'MeanSaleOrder',\n",
    "                                   'MeanPSale', 'MaxOrderMonth', 'MaxOrderMonth', 'MaxOrderDay', 'Label', 'TRProd', \n",
    "                                   'SETSaleQta', 'SESaleQtaOrder', 'SEShoppingDays', 'DProd', 'TSale', 'TOrder'], errors='ignore')\n",
    "df_class = df_aux.copy()\n",
    "df_class.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df_class.pop('Label_num')\n",
    "train_set, test_set, train_label, test_label = train_test_split(df_class, label, stratify =label, test_size=0.35)\n",
    "print(f\"Class HighSpend\\nTraining: {len(train_label[train_label == 0])}\\nTest: {len(test_label[test_label == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=3, min_samples_split=17, min_samples_leaf=20)\n",
    "dt = dt.fit(train_set, train_label)\n",
    "classes = ['High_Spend','Low_Spend','Med_Spend']\n",
    "dot_data = tree.export_graphviz(dt, out_file=None, feature_names=list(train_set.columns), class_names=classes, filled=True, rounded=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred_dt = dt.predict(train_set)\n",
    "test_pred_dt = dt.predict(test_set)\n",
    "report_scores(test_label, test_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
